{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c96ce0-fef6-4620-8eca-18a8d3736747",
   "metadata": {},
   "source": [
    "Задание:\n",
    "> Run manually configured Kafka Cluster with 3+ instances\n",
    "> \n",
    "> Use either Zookeper or KRaft\n",
    "> \n",
    "> Create simulated stream workload (logs, payments, clicks, etc.)\n",
    "> \n",
    "> Create consumers\n",
    "> \n",
    "> Simulate outage of minority, observe availability\n",
    "> \n",
    "> Simulate outage of majority, observe unavailability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7bd6e-a834-42df-8733-29d998dd0d59",
   "metadata": {},
   "source": [
    "Хочу Raft и отдельную ноду Кафки в качестве контроллера. Интересно посмотреть, что произойдёт с кластером при падении контроллера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54526ea5-e4b2-43b8-9fe0-5620f8f7c415",
   "metadata": {},
   "source": [
    "Протокол CONTROLLER используется только для связи между контроллерами (выборы лидера, метаданные). Для обычного брокера (`process.roles=broker`) не нужен CONTROLLER-листенер, но нужно знать, где контроллера можно найти (`controller.quorum.voters`). Брокер подключается к контроллеру через его CONTROLLER-листенер (порт 19093 по умолчанию) для:\n",
    "* Регистрации при старте\n",
    "* Регулярных heartbeat-ов\n",
    "* Получения команд (назначение лидера партиции, обновление метаданных: топики, лидеры партиций)\n",
    "* Уведомляет о статусе in-sync реплик\n",
    "\n",
    "Обратный канал отсутствует. Контроллер не подключается к брокеру — все команды отправляются как ответы на heartbeat-ы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b03f5-4220-4cb4-ae0b-89276d8f4f8d",
   "metadata": {},
   "source": [
    "Конфиги контроллеру и брокеру нужны разные. Брокерам оставляю то, что связано с топиками, убираю у них controller-слушателя. Насчёт некоторых настроек было сложно определить, кому они нужны - чистому контроллеру или чистому брокеру:\n",
    "\n",
    "* `unclean.leader.election.enable` нужна брокерам несмотря на то, что выбором лидера занимается контроллер. Контроллер всегда старается назначить лидера из ISR (in-sync replicas), независимо от `unclean.leader.election.enable`. Если реплики из ISR живы — контроллер выбирает одну из них. Если ISR пуст - контроллер смотрит значение `unclean.leader.election.enable` на брокерах. Так что этот параметр нужен только на брокерах и не нужен на контроллере\n",
    "* `auto.leader.rebalance.enable` нужна брокерам. Брокеры следят за своей собственной нагрузкой и запрашивают ребалансировку у контроллеров, если слишком во многих партициях они назначены лидерами. Контроллеры только исполняют ребалансировку, но не инициируют (UPD позднее окажется, что это не так)\n",
    "* `group.initial.rebalance.delay.ms` нужна брокерам. Ребалансировки в консьюмер-группах инициируют брокеры - брокеры, назначенные координаторами консьюмер-групп. У каждой консьюмер-группы есть свой координатор, выбранный из брокеров (а не контроллеров)\n",
    "* `default.replication.factor` нужен на контроллере, иначе просто не работает репликация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab735d3c-15fc-484b-ad6c-c8b5da9e35de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting metadata directory ./tmp/c4 with metadata.version 3.9-IV0.\n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-storage.sh format -t $(./kafka/bin/kafka-storage.sh random-uuid) -c ./kafka/a-config/controller.1.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038f094-802b-470a-b753-7c99cbb24125",
   "metadata": {},
   "source": [
    "Затем запускаю трёх брокеров и одного контроллера и создаю топик `page-views`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45f69608-5dad-46ab-9c49-a124d67e28cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic user-events.\n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --create --topic user-events --partitions 8 --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2d6399c-c367-43e1-998c-604aa8555b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: user-events\tTopicId: 3lls2lKPSl2Ljop6-DkC9Q\tPartitionCount: 8\tReplicationFactor: 3\tConfigs: min.insync.replicas=2,unclean.leader.election.enable=false\n",
      "\tTopic: user-events\tPartition: 0\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 1\tLeader: 2\tReplicas: 2,3,1\tIsr: 2,3,1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 2\tLeader: 3\tReplicas: 3,1,2\tIsr: 3,1,2\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 3\tLeader: 3\tReplicas: 3,2,1\tIsr: 3,2,1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 4\tLeader: 2\tReplicas: 2,1,3\tIsr: 2,1,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 5\tLeader: 1\tReplicas: 1,3,2\tIsr: 1,3,2\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 6\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 7\tLeader: 2\tReplicas: 2,3,1\tIsr: 2,3,1\tElr: \tLastKnownElr: \n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --describe --topic user-events --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96827ba5-3686-40ed-affe-3974db25cc31",
   "metadata": {},
   "source": [
    "Пробую писать в топик c `acks=all` в трёх условиях:\n",
    "* когда весь кластер жив\n",
    "* когда не отвечает один инстанс брокера\n",
    "* когда нет достаточного количества in-sync реплик (в моей конфигурации это происходит когда нет двух из трёх инстансов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a002be6-b179-4e2f-989d-bed2b5b488c2",
   "metadata": {},
   "source": [
    "![image.png](pic/_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf3aae-366c-4b4f-9328-f65e8552a303",
   "metadata": {},
   "source": [
    "1. Когда весь кластер жив, всё хорошо. Параметр `acks=all` не означает \"ждать подтверждения от всех созданных реплик\" (`default.replication.factor`), а именно от всех реплик, которые сейчас в ISR. Первоначально в топике три ISR, так что если все продьюсеры будут записывать с `acks=all`, то им всегда придётся дожидаться записи на три реплики. Но если появится один продьюсер с `acks=1` или `acks=0`, он нарушит ISR=3. Лидер партиции будет записывать сообщения быстрее, чем другие реплики - реплицировать. В этом случае в моменте ISR может быть равно 1 или 2, и продьюсеры с `acks=all` часто будут ждать записи не на три реплики, а на две, как заложено в `min.insync.replicas`.\n",
    "2. Когда падает один брокер, то продьюсеру не удаётся запись в те партиции, где упавший брокер был лидером. Он перезапрашивает метаданные у любого живого брокера, узнает нового лидера партиции и направляет сообщение ему. Так что продьюсер замечает исчезновение одного из брокеров, но с этим справляется.\n",
    "3. Когда падает два из трёх брокеров, запись останавливается, потому что становится невозможно записать сообщение, не нарушив `min.insync.replicas=2`.\n",
    "\n",
    "Если заменить `acks=all` на `acs=1`, достаточно будет подтверждения записи на лидер-реплику - единственного выжившего брокера. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ddfa21-fc43-4f4d-b59d-d4a405133a64",
   "metadata": {},
   "source": [
    "![image.png](pic/_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40a516-83f6-4d60-ae1b-cd6b5b450779",
   "metadata": {},
   "source": [
    "Когда упавшие реплики вернутся в строй, они скопируют себе с лидера те сообщения, которые появились в топике, пока что они были оффлайн. Пока репликация не будет завершена, они не смогут взять лидерство над партицией из-за настройки `unclean.leader.election.enable=false`\n",
    "\n",
    "Поставлю `auto.leader.rebalance.enable=true` и `leader.imbalance.check.interval.seconds=1000` на контроллере и `auto.leader.rebalance.enable=false` на брокерах, чтобы увидеть, произойдёт ребаланс или нет после возвращения брокеров в строй."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "140d55f8-e1a5-40b7-94ce-81b612801a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: user-events\tTopicId: 3lls2lKPSl2Ljop6-DkC9Q\tPartitionCount: 8\tReplicationFactor: 3\tConfigs: min.insync.replicas=2,unclean.leader.election.enable=false\n",
      "\tTopic: user-events\tPartition: 0\tLeader: 1\tReplicas: 1,2,3\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 1\tLeader: 1\tReplicas: 2,3,1\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 2\tLeader: 1\tReplicas: 3,1,2\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 3\tLeader: 1\tReplicas: 3,2,1\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 4\tLeader: 1\tReplicas: 2,1,3\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 5\tLeader: 1\tReplicas: 1,3,2\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 6\tLeader: 1\tReplicas: 1,2,3\tIsr: 1\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 7\tLeader: 1\tReplicas: 2,3,1\tIsr: 1\tElr: \tLastKnownElr: \n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --describe --topic user-events --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cd3e5-1663-4223-b882-07f09bde8fa8",
   "metadata": {},
   "source": [
    "Жду 10 секунд, выполняю ещё раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c12e913d-7be3-44c3-8e9d-fa5df37650ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: user-events\tTopicId: 3lls2lKPSl2Ljop6-DkC9Q\tPartitionCount: 8\tReplicationFactor: 3\tConfigs: min.insync.replicas=2,unclean.leader.election.enable=false\n",
      "\tTopic: user-events\tPartition: 0\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 1\tLeader: 2\tReplicas: 2,3,1\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 2\tLeader: 3\tReplicas: 3,1,2\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 3\tLeader: 3\tReplicas: 3,2,1\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 4\tLeader: 2\tReplicas: 2,1,3\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 5\tLeader: 1\tReplicas: 1,3,2\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 6\tLeader: 1\tReplicas: 1,2,3\tIsr: 1,2,3\tElr: \tLastKnownElr: \n",
      "\tTopic: user-events\tPartition: 7\tLeader: 2\tReplicas: 2,3,1\tIsr: 1,2,3\tElr: \tLastKnownElr: \n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --describe --topic user-events --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb9591-6200-475e-88b8-5ca8492ef62c",
   "metadata": {},
   "source": [
    "Значит, настройка ребалансировки лидера нужна на контроллерах и неверно было утрерждение, что именно брокеры инициируют ребалансировку. Дизлайк Deepseek-у! Вероятно, и утверждение про то, что `unclean.leader.election.enable` нужна только на брокере, тоже не совсем верно. Но я не нашёл способа как это проверить - надо было бы остановить репликацию на возвращённом в строй брокере и убедится, что он не становится лидером, а я не уверен, что можно командой остановить репликацию. Можно как-то замедлить сеть или заблочить порт, но я не стал заморачиваться. \n",
    "\n",
    "Теперь добавлю двух консьюмеров-одногруппников и выключу контроллера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47848164-4740-4810-81d0-ce7ae170e973",
   "metadata": {},
   "source": [
    "![image.png](pic/_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57e99f-3de7-441d-96ea-53dcf7271202",
   "metadata": {},
   "source": [
    "![image.png](pic/_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6441b-f4b6-4eae-bbe0-d33f4152beab",
   "metadata": {},
   "source": [
    "Запись в топик продолжилась, чтение из топиков продолжилось, кластер целиком доступен, но в логах брокеров началось сумасшествие. Команда `./kafka/bin/kafka-topics.sh --describe --topic user-events --bootstrap-server localhost:19092,localhost:19091,localhost:19090` теперь зависает и не выполняется несмотря на то, что в `--bootstrap-server` перечислены живые хосты. Предполагаю, что другие команды (например, команда сбалансировать лидеров партиций) тоже подвиснут. Репликация не остановилась: я делаю этот вывод, исходя из того, что продьюсеру с `acks=all` удаётся запись в топик, несмотря на отсутствие контроллера. Пробую убить одного брокера через `SIGTERM`, но брокер не хочет закрываться. Узнаю его pid и убиваю силой через `kill -9`.\n",
    "\n",
    "После этого продьюсер и консьюмер останавливаются, хотя ISR=2, и по идее можно было бы писать дальше. Спустя минуту у продьюсера появляются таймауты от живых нод Кафки: `localhost:19091/2: Timed out ProduceRequest in flight`, что говорит о том, что живые брокеры перестали принимать запросы на запись. Судя по логам, они бесконечно пытаются подключиться к упавшему брокеру из треда `ReplicaFetcher` и к котроллеру из `NodeToControllerChannelManager`. Притом на остановку процессов не влияет то, была ли выключенная нода лидером в каких-то партициях топика. Я повторял эксперимент по разному - и от того, была ли выключенная нода лидером, зависит лишь то, появятся ли сразу после её выключения ошибки `Disconnected` в логах продьюсера и консьюмера (на скриншоте ниже они есть).\n",
    "\n",
    "Если запустить нового консьюмера из новой группы, он попытается установить соединение с выключенным брокером даже если убрать его из bootstrap-servers. Видимо, за отсутствием контроллера метаданные про топик консьюмер получил от одного из живых брокеров, а у него эти метаданные (тоже из-за отсутствия контроллера) неактуальные - и ведут на выключенную ноду.\n",
    "\n",
    "Предполагаю, что без контроллера кластер Кафки может штатно работать только до тех пор, пока не случится какое-то событие, которое потребует участия контроллера. Если такое событие происходит, гаснут и продьюсеры, и консьюмеры. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7b7f8-c375-4bb6-b682-47abe8c79bf5",
   "metadata": {},
   "source": [
    "![image.png](pic/_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd72c7-269d-4e9f-b956-989174bb049e",
   "metadata": {},
   "source": [
    "Если в этот момент вернуть контроллера, то оставшиеся в живых два брокера, которых я тоже пытался убить, наконец позволяют себе упасть. В логах от них остаются такие сообщения:\n",
    "```\n",
    "[2025-07-20 13:15:52,896] INFO [BrokerLifecycleManager id=2] The broker is in PENDING_CONTROLLED_SHUTDOWN state, still waiting for the active controller. (kafka.server.BrokerLifecycleManager)\n",
    "[2025-07-20 13:15:53,294] ERROR [BrokerServer id=2] Timed out waiting for the controller to approve controlled shutdown (kafka.server.BrokerServer)\n",
    "[2025-07-20 13:15:53,294] INFO [BrokerLifecycleManager id=2] beginShutdown: shutting down event queue. (org.apache.kafka.queue.KafkaEventQueue)\n",
    "[2025-07-20 13:15:53,294] INFO [BrokerLifecycleManager id=2] Transitioning from PENDING_CONTROLLED_SHUTDOWN to SHUTTING_DOWN. (kafka.server.BrokerLifecycleManager)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801caf96-03d8-4142-8e24-42bff464160e",
   "metadata": {},
   "source": [
    "Они ждали контроллера, дождались, но контроллер не успел им ответить (`Timed out waiting for the controller to approve`). В конечном итоге, контроллеру тоже нужно время на запуск, прежде чем он будет готов обрабатывать запросы с кластера.\n",
    "\n",
    "Если повторить инцидент, но не гасить брокеров, то после возвращения контроллера в кластер (в котором все три брокера живы) всё станет снова хорошо. Возобновятся и запись, и чтение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
