{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb04c4c-8c10-43e2-aced-388f773b000f",
   "metadata": {},
   "source": [
    "Задание:\n",
    "> Run Streams on top of the cluster from previous homework\n",
    "> \n",
    "> Create simple mapper for any of the simulated topic\n",
    "> \n",
    "> Implement simple aggregate processor\n",
    "> \n",
    "> Implement join processor\n",
    "> \n",
    "> Could be done with Kafka Streams or any other approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373be72b-f52a-4903-9359-27b88be1ae44",
   "metadata": {},
   "source": [
    "Для потоковой обработки хочу попробовать Apache Flink. Это фреймворк, написанный на Java и Scala, у которого реализован API. Для для взаимодействия с API можно использовать библиотеку `pyflink` на Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1e6a1-67fa-47f0-b49c-efa2250eb067",
   "metadata": {},
   "source": [
    "1. Создам топик `purchases`. Пусть он заполняется из producer.py параллельно с топиком `user-events`. Если в `user-events` приходит событие с `event_type=purchase`, то в течение 5 секунд до/после я ожидаю появления в `purchases` стоимости заказа. В 20% случаев стоимость заказа пусть приходит с задержкой более 5 секунд. В качестве времени требуется использовать продуктовое время (время события, а не время записи в Kafka или попадания во Flink). Насчёт пользователей - пусть у нас их будет всего 20 уникальных.\n",
    "2. Создам топик `visits`. В него пусть попадают события из `user-events`, обогащённые ценой из `purchases` и размеченные по сессиям. Окно сессии - 20 секунд (между событиями одной сессии проходит не более 20 секунд). Идентификатор сессии генерирую случайным образом на лету. Если внутри сессии были покупки, обогащённые из топика `purchases`, то растягиваю цену `amount` (последнюю по `timestamp`-у) на все хиты в сессии. \n",
    "3. Создам топик `suspicious-visits`. В него буду записывать идентификаторы таких сессий, в которых нахожу что-то подозрительное:\n",
    "    * либо суммарное кол-во событий в сессии больше 5. Обозначаю как `type=1`\n",
    "    * либо в сессии нет ни одного события `event_type=page-view`, хотя есть другие. Обозначаю как `type=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cefe3e9-d28a-4761-b3c6-c99aff312e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic purchases.\n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --create --topic purchases --partitions 8 --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2c5e4ef-e641-42d3-bfe8-f2bcedfd6208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic visits.\n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --create --topic visits --partitions 8 --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ada1a159-1189-4a3c-813a-ffc42b2d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic suspicious-visits.\n"
     ]
    }
   ],
   "source": [
    "!./kafka/bin/kafka-topics.sh --create --topic suspicious-visits --partitions 8 --bootstrap-server localhost:19092,localhost:19091,localhost:19090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fed565-76a2-4b52-9aab-fd3523a9e0d7",
   "metadata": {},
   "source": [
    "Вместе с установочными файлами Flink предлагает из коробки несколько примеров по запуску задач на Python. Буду адаптировать примеры, взятые оттуда. Скачиваю .jar коннектор к Kafka и подключаю его к скрипту через .add_jars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fc565915-768d-420f-9f41-743f9125e91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cluster.\n",
      "Starting standalonesession daemon on host LAPTOP-CT070LG3.\n",
      "Starting taskexecutor daemon on host LAPTOP-CT070LG3.\n"
     ]
    }
   ],
   "source": [
    "!~/flink/bin/start-cluster.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "475d3505-8f73-40e1-b9de-4acf37e52b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/timosha/flink/examples/python\u001b[00m\n",
      "├── \u001b[01;34mdatastream\u001b[00m\n",
      "│   ├── basic_operations.py\n",
      "│   ├── \u001b[01;34mconnectors\u001b[00m\n",
      "│   │   ├── elasticsearch.py\n",
      "│   │   ├── kafka_avro_format.py\n",
      "│   │   ├── kafka_csv_format.py\n",
      "│   │   ├── kafka_json_format.py\n",
      "│   │   └── pulsar.py\n",
      "│   ├── event_time_timer.py\n",
      "│   ├── process_json_data.py\n",
      "│   ├── state_access.py\n",
      "│   ├── streaming_word_count.py\n",
      "│   ├── \u001b[01;34mwindowing\u001b[00m\n",
      "│   │   ├── session_with_dynamic_gap_window.py\n",
      "│   │   ├── session_with_gap_window.py\n",
      "│   │   ├── sliding_time_window.py\n",
      "│   │   ├── tumbling_count_window.py\n",
      "│   │   └── tumbling_time_window.py\n",
      "│   └── word_count.py\n",
      "└── \u001b[01;34mtable\u001b[00m\n",
      "    ├── basic_operations.py\n",
      "    ├── mixing_use_of_datastream_and_table.py\n",
      "    ├── multi_sink.py\n",
      "    ├── \u001b[01;34mpandas\u001b[00m\n",
      "    │   ├── conversion_from_dataframe.py\n",
      "    │   └── pandas_udaf.py\n",
      "    ├── process_json_data.py\n",
      "    ├── process_json_data_with_udf.py\n",
      "    ├── streaming_word_count.py\n",
      "    ├── \u001b[01;34mwindowing\u001b[00m\n",
      "    │   ├── over_window.py\n",
      "    │   ├── session_window.py\n",
      "    │   ├── sliding_window.py\n",
      "    │   └── tumble_window.py\n",
      "    └── word_count.py\n",
      "\n",
      "6 directories, 29 files\n"
     ]
    }
   ],
   "source": [
    "!tree ~/flink/examples/python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533e80a-92a9-47fb-bf41-80aba0f698f0",
   "metadata": {},
   "source": [
    "Для начала просто настрою подключение к Кафке. Читаю топик с конца. Прочитанные сообщения отправляю в вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "844a1759-3621-47e7-a0f0-0930a5201cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyflink.common import Types\n",
    "from pyflink.common.watermark_strategy import WatermarkStrategy\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.datastream.connectors.kafka import KafkaSource, KafkaOffsetsInitializer\n",
    "from pyflink.datastream.formats.json import JsonRowDeserializationSchema\n",
    "\n",
    "\n",
    "def process_user_events(env):\n",
    "    deserialization_schema = JsonRowDeserializationSchema.Builder() \\\n",
    "        .type_info(Types.ROW_NAMED(\n",
    "            ['event_type', 'user_id', 'page_id', 'timestamp'],\n",
    "            [Types.STRING(), Types.INT(), Types.INT(), Types.FLOAT()])) \\\n",
    "        .build()\n",
    "    source = KafkaSource.builder() \\\n",
    "        .set_bootstrap_servers(\"localhost:19092,localhost:19091,localhost:19090\") \\\n",
    "        .set_topics(\"user-events\") \\\n",
    "        .set_group_id(\"flink-group\") \\\n",
    "        .set_starting_offsets(KafkaOffsetsInitializer.latest()) \\\n",
    "        .set_value_only_deserializer(deserialization_schema) \\\n",
    "        .build()\n",
    "\n",
    "    stream = env.from_source(source, WatermarkStrategy.no_watermarks(), source_name=\"user-events\")\n",
    "    stream.map(lambda row: (\n",
    "        row[\"event_type\"],\n",
    "        row[\"user_id\"],\n",
    "        row[\"page_id\"],\n",
    "        datetime.fromtimestamp(row[\"timestamp\"]).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    )).print()\n",
    "    env.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a12c013-9c08-4320-b0cd-abdc06b57719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6> ('page-view', 4, 8, '2025-07-21 19:17:04')\n",
      "11> ('purchase', 2, 55, '2025-07-21 19:17:04')\n",
      "9> ('page-view', 3, 84, '2025-07-21 19:17:04')\n",
      "8> ('click', 7, 81, '2025-07-21 19:17:04')\n",
      "6> ('page-view', 4, 8, '2025-07-21 19:17:04')\n",
      "6> ('purchase', 4, 63, '2025-07-21 19:17:04')\n",
      "6> ('page-view', 14, 92, '2025-07-21 19:17:04')\n",
      "11> ('purchase', 2, 55, '2025-07-21 19:17:04')\n",
      "8> ('click', 7, 81, '2025-07-21 19:17:04')\n",
      "9> ('page-view', 3, 84, '2025-07-21 19:17:04')\n",
      "9> ('click', 8, 60, '2025-07-21 19:17:04')\n",
      "6> ('purchase', 4, 63, '2025-07-21 19:17:04')\n",
      "6> ('page-view', 14, 92, '2025-07-21 19:17:04')\n",
      "6> ('page-view', 14, 56, '2025-07-21 19:17:04')\n",
      "11> ('page-view', 2, 81, '2025-07-21 19:17:04')\n",
      "11> ('page-view', 2, 81, '2025-07-21 19:17:04')\n",
      "6> ('page-view', 14, 56, '2025-07-21 19:17:04')\n",
      "9> ('click', 8, 60, '2025-07-21 19:17:04')\n",
      "9> ('click', 13, 93, '2025-07-21 19:17:04')\n",
      "9> ('click', 13, 93, '2025-07-21 19:17:04')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.add_jars(\"file:///home/timosha/flink/lib/flink-sql-connector-kafka-4.0.0-2.0.jar\")\n",
    "    process_user_events(env)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcd130-0e7d-45f2-adfb-027ad3c960ce",
   "metadata": {},
   "source": [
    "Или из консоли:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667b12d-b9ab-4742-bb2d-0856ccea4dfd",
   "metadata": {},
   "source": [
    "![image.png](./pic/_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cf6bd-db71-4ad7-8af2-b82a19d4356b",
   "metadata": {},
   "source": [
    "Теперь подготовлю разметку по сессиям с окном в 30 секунд. Результат будет пушится в `visits`, а я запущу консьюмера для чтения из топика `visits` в консоль.\n",
    "\n",
    "```python\n",
    "session_visits = user_events_stream\\\n",
    "    .key_by(lambda e: e['user_id'], key_type=Types.INT()) \\\n",
    "    .window(EventTimeSessionWindows.with_gap(Time.seconds(30))) \\\n",
    "    .process(SessionGenerator(), output_type=visits_serialization_schema)\n",
    "session_visits.sink_to(visits_sinker)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b56dba-be17-448b-8fe0-f02e330fe583",
   "metadata": {},
   "source": [
    "![image.png](./pic/_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a782b-3763-4413-8b5b-de959e6eb904",
   "metadata": {},
   "source": [
    "Всё верно:\n",
    "* у событий внутри одного окна одинаковый `session_id`\n",
    "* окно открыто до тех пор, пока после последнего из событий не пройдёт больше чем 20 секунд. Например, по пользователю `user_id=5` видно, что его сессия продолжалась суммарно 26 секунд.\n",
    "* сессию пользователя с `user_id=12` мы ещё не получили, потому что окно для неё ещё не закрыто. а у пользователя `user_id=6` разметили уже две сессии, в которых по одному хиту. Так получилось из-за того, что между хитами прошло больше 20 секунд, и после последнего прошло больше 20 секунд.\n",
    "\n",
    "Я не смог выяснить, почему Pyflink не отправляет строчку сразу как только закрывает окно, а с задержкой до нескольких минут: возможно, это как-то связано с ватерлиниями (watermark) или с тем, что я поставил параллелизм = 1. Без параллелизма, с другой стороны, просто ничего не работало, а с ватерлинией всё должно быть нормально. Pyflink тяжело дебажить - нет ни внятной документации, ни файлов с логами. Трейсбек любой ошибки занимает по двести строк. Нейросети путаются между последней и предпоследней версиями фреймворка (которые во много несовместимы) и версией API на Java, в которой имплементировано больше фичей, чем в Pyflink. Кошмар! Тысячу раз пожалел, что устроил себе это развлечение!\n",
    "\n",
    "Сделаю мониторинг подозрительных сессий:\n",
    "* либо суммарное кол-во событий в сессии больше 5. Обозначаю как type=1\n",
    "* \n",
    "либо в сессии нет ни одного события event_type=page-view, хотя есть другие. Обозначаю как type=2\n",
    "\n",
    "Эту аггрегацию, кажется, проще всего выполнить сразу вместе с разметкой сессии: пока что все хиты, входящие в сессию, собраны вместе. Попробую модифицировать `SessionGenerator` - пусть онгенерируета данные для обоих топиков,а строкие будут потом фильтроваться кажаяй - в сво топикй.\n",
    "\n",
    "```python\n",
    "class SessionGenerator(ProcessWindowFunction):\n",
    "    def process(self, key, context, elements):\n",
    "        session_id = str(uuid4()).split('-')[0]\n",
    "        events = list(elements)\n",
    "        for element in elements:\n",
    "            yield Row(\n",
    "                session_id=session_id,\n",
    "                user_id=element['user_id'],\n",
    "                event_type=element['event_type'],\n",
    "                page_id=element['page_id'],\n",
    "                amount=element['amount'] if 'amount' in element._fields else 0,\n",
    "                timestamp=element['timestamp'],\n",
    "                type=None)\n",
    "            \n",
    "        # проверка на подозрительность\n",
    "        suspicious_type = None\n",
    "        if len(events) > 3:\n",
    "            suspicious_type = 1\n",
    "        elif not any(e['event_type'] == 'page-view' for e in events):\n",
    "            suspicious_type = 2\n",
    "            \n",
    "        if suspicious_type is not None:\n",
    "            yield Row(\n",
    "                session_id=session_id,\n",
    "                user_id=key,\n",
    "                event_type=None,\n",
    "                page_id=None,\n",
    "                amount=None,\n",
    "                timestamp=None,\n",
    "                type=suspicious_type)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf6cee-5950-4786-a9ee-85a2f0e7a3bf",
   "metadata": {},
   "source": [
    "![image.png](./pic/_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c093de-fbdd-4db4-a320-71896df0189f",
   "metadata": {},
   "source": [
    "Теперь сделаю джойн на лету с `purchases`. \n",
    "\n",
    "В Pyflink нет джойна из коробки, но есть соединение по ключу `connect`, которое можно дополнить своей логикой, расширив класс `CoProcessFunction`.\n",
    "\n",
    "> Извините за недоразумение! Вы абсолютно правы, и я благодарю за указание на ошибку. В PyFlink 2.0 (основанном на Apache Flink 1.14) метод interval_join не доступен в API DataStream для Python, хотя он существует в Java/Scala API. Это ограничение PyFlink, и моя предыдущая уверенность была ошибочной из-за путаницы с документацией Java API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c1817a30-8c46-4fd7-afc0-e2d0b850903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.datastream.functions import CoProcessFunction\n",
    "\n",
    "class EnrichPurchaseFunction(CoProcessFunction):\n",
    "    def __init__(self):\n",
    "        self.purchase_state = None\n",
    "        self.events_state = None\n",
    "\n",
    "    def open(self, context):\n",
    "        # Создаю стейт, в который буду сохранять покупки и события без пары.\n",
    "        # Например, покупку, которая пришла раньше события покупки\n",
    "        self.purchase_state = context.get_list_state(\n",
    "            ListStateDescriptor(\"purchases\", Types.ROW_NAMED(\n",
    "                ['amount', 'user_id', 'page_id', 'timestamp'],\n",
    "                [Types.INT(), Types.INT(), Types.INT(), Types.INT()])))\n",
    "        self.events_state = context.get_list_state(\n",
    "            ListStateDescriptor(\"events\", Types.ROW_NAMED(\n",
    "                ['event_type', 'user_id', 'page_id', 'timestamp'],\n",
    "                [Types.STRING(), Types.INT(), Types.INT(), Types.INT()])))\n",
    "\n",
    "    def process_element1(self, user_event, ctx):\n",
    "        # событие из user_events_stream\n",
    "        event_timestamp = user_event['timestamp'] * 1000\n",
    "        for purchase in self.purchase_state:\n",
    "            purchase_timestamp = purchase['timestamp'] * 1000\n",
    "            if abs(event_timestamp - purchase_timestamp) <= 5000:  # ±5 секунд\n",
    "                yield Row(\n",
    "                    user_id=user_event['user_id'],\n",
    "                    event_type=user_event['event_type'],\n",
    "                    page_id=user_event['page_id'],\n",
    "                    timestamp=user_event['timestamp'],\n",
    "                    amount=purchase['amount'])\n",
    "                break\n",
    "        else:\n",
    "            if user_event['event_type'] == 'purchase':\n",
    "                self.events_state.add(user_event)\n",
    "            yield Row(\n",
    "                user_id=user_event['user_id'],\n",
    "                event_type=user_event['event_type'],\n",
    "                page_id=user_event['page_id'],\n",
    "                timestamp=user_event['timestamp'],\n",
    "                amount=0)\n",
    "\n",
    "    def process_element2(self, purchase, ctx):\n",
    "        # событие из purchases\n",
    "        purchase_timestamp = purchase['timestamp'] * 1000\n",
    "        for event in self.events_state:\n",
    "            event_timestamp = event['timestamp'] * 1000\n",
    "            if abs(purchase_timestamp - event_timestamp) <= 5000:\n",
    "                yield Row(\n",
    "                    user_id=event['user_id'],\n",
    "                    event_type=event['event_type'],\n",
    "                    page_id=event['page_id'],\n",
    "                    timestamp=event['timestamp'],\n",
    "                    amount=purchase['amount'])\n",
    "                break\n",
    "        else:\n",
    "            self.purchase_state.add(purchase)\n",
    "\n",
    "    def on_timer(self, timestamp, ctx):\n",
    "        # Очистка старых покупок (опционально, для управления размером состояния)\n",
    "        current_watermark = ctx.get_current_watermark()\n",
    "        updated_purchases = [\n",
    "            p for p in self.purchase_state\n",
    "            if p['timestamp'] * 1000 >= current_watermark - 5000]\n",
    "        updated_events = [\n",
    "            p for p in self.updated_events\n",
    "            if p['timestamp'] * 1000 >= current_watermark - 5000]        \n",
    "        self.purchase_state.clear()\n",
    "        self.updated_events.clear()\n",
    "        self.purchase_state.update(updated_purchases)\n",
    "        self.updated_events.update(updated_events)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995661e4-3e04-411e-a077-17c5cde52427",
   "metadata": {},
   "source": [
    "Отправляю для отладки результат джойна в вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29319aba-d838-4c0d-99ba-ca818cddc295",
   "metadata": {},
   "source": [
    "![image.png](./pic/_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e687a92-b366-41ab-998d-fb6c3b0bcaa3",
   "metadata": {},
   "source": [
    "Всё корректно. Если покупка приходит как до/после события в течение 5 секунд (по модулю), она успешно присоединяется к событию. При задержке более 5 секунд оплата из топика `purchases` не присоединяется.\n",
    "\n",
    "Теперь поджойнённый стрим подкладываю в качестве источника под разметку сессий, которая уже протестирована и работает. Дорабатываю разметку так, чтобы растягивать приджойненный `amount` на все хиты в сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67567233-07aa-4cd6-9c27-8a5f313c3002",
   "metadata": {},
   "source": [
    "![image.png](./pic/_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6a2a6-f338-4b31-aa3f-a391f369ff1d",
   "metadata": {},
   "source": [
    "Всё готово!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
